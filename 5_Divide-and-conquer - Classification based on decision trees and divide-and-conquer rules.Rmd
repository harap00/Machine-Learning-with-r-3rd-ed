---
title: "Divide-and-conquer - Classification based on decision trees and divide-and-conquer
  rules"
---

# 第５章

# 　分割統治 ―決定木と分割ルールに基づく分類

------------------------------------------------------------------------

-   決定木と分割ルールがデータを重要なセグメントに「貪欲に」分割する仕組み

-   C5.0、IR、RIPPERなど最もよく使われている決定木と分割ルール学習機

-   危険な融資や毒キノコの識別など、現実的な分類タスクでのこれらのアルゴリズムの使い方

# 5.1 決定木を理解する

　決定木アルゴリズムの大きな利点は、このフローチャートのような木構造の用途が学習器に限られないことである。多くの決定木アルゴリズムでは、モデルの出力は人が読める形式の（ヒューマンリーダブルな）構造である。この出力から、このモデルが特定のタスクでどれくらいうまくいくか、うなくいかないとしたらそれはなぜかについてのヒントが得られる。

-   **格付けモデル**\
    申請を却下する基準を明確に文章化し、偏見を排除する

-   **顧客行動に関する市場調査**\
    経営陣や広告代理店度満足度や解約率などを共有する

-   **疾患の診断**\
    臨床検査、症状、疾患進行率などに基づいて疾患を診断する

### 5.1.1　分割統治

　決定木アルゴリズムは、データを分割統治するために各枝をたどっていき、どのつど新しい決定ノードを作成するのに最適な特徴量を選択する。そして、終了時条件が満たされるまで、このプロセスを繰り返す。分割統治が終了するのは、次のいずれかの条件が満たされたときである。

-   そのノードのすべて（またはほぼすべて）のインスタンスが同じクラスに所属している

-   インスタンスを識別するための特徴量が残っていない

-   決定木が事前に定義した最大サイズに達している

### 5.1.2　C5.0アルゴリズム

　C5.0アルゴリズムは、ほとんどのしゅるいでの問題にそのまま適用できるため、決定木を生成するための業界標準となっている。C5.0で構築した決定木の性能は、より高度なが機械学習モデルとほぼ同じであり、しかも理解したりデプロイしたりするのがずっと容易である。それに加えて、次の表に示すように、このアグ後リズムの短所はそれほど重大なものではなく、大部分は回避できる。

+-----------------------------------------------+--------------------------------------------------+
| 長所                                          | 短所                                             |
+===============================================+==================================================+
| -   様々な種類の問題にうまく対処する汎用\     | -   レベルの数が多い特徴量基づいて分割を行\      |
|     分類器                                    |     うようにバイアスがかかりがち                 |
|                                               | -   モデルが過学習または学習不足に陥りやすい     |
| -   高度に自動化された学習プロセス。数値特徴\ | -   軸に平行な分割に依存するため、関係をうま\    |
|     量や名義特徴量だけでなく欠損値にも対処で\ |     くモデル化できないことがある                 |
|     きる                                      | -   訓練データの小さな変化によって決定ロジッ\    |
|                                               |     クが大きく変化することがある                 |
| -   重要度の低い特徴量を除外                  | -   大規模な決定木は解釈が難しいことがあり、\    |
|                                               |     直感に反する決定を行うように見えることがある |
| -   小規模なデータセットでも大規模なデータ\   |                                                  |
|     セットでも利用できる                      |                                                  |
|                                               |                                                  |
| -   数学的な知識がなくても解釈できるモデルが\ |                                                  |
|     得られる（比較的小さい決定木の場合）      |                                                  |
|                                               |                                                  |
| -   他の複雑なモデルよりも効率的              |                                                  |
+-----------------------------------------------+--------------------------------------------------+

#### 最適な分割を選択する

　インスタンスのグループが１つのクラスのみに所属している度合いを**純度**（purity）と呼ぶ。C5.0は**エントロピー**（entropy）を使っている。\
　一般にエントロピーは**ビット**（bit）で表される。クラスが２つしかない場合、エントロピーは０から１の範囲の値となる。クラスがｎ個の場合は、０から$log2(n)$の範囲の値になる。どの場合も、最小値はインスタンスが完全に欽一であることを表し、最大値はデータが可能な限り多様で、どのグループにもほんの僅かな純度すら認められないことを意味する。

$$
\begin{aligned} 
Entropy(S) &= \sum_{i=1}^{c}{-p_i\log_2{(p_i)}}\\
\\
(S) &: データセグメント\\
c &: クラスのレベルの個数\\
p_i &: クラスレベルiに分類される値の割合
\end{aligned}
$$

```{r}
-0.6 * log2(0.60) - 0.40 * log2(0.40)
```

　クラスが２つの場合に考えられるすべてのパターンのエントロピーを可視化してみる。一方のクラスに分類され得るインスタンスの割合を$x$とすれば、もう一方のクラスに分類されるインスタンスの割合は$(x-1)$である。

```{r fig.height=5, fig.width=5}
curve(-x * log2(x) - (1 - x) * log2(1 - x), 
      col = 'red', 
      xlab = 'x', 
      ylab = 'Entropy', 
      lwd =4,
      main = 'データが一方のクラスに分類される割合に対するエントロピー'
      )
```

情報利得$IG$は分割前のセグメント$(S_1)$と分割後のセグメント$(S_2)$でのエントロピーの差として計算する。\
$$
IG(F)=Entropy(S_1)-Entropy(S_2)
$$

複数回階層的に分割が発生するので、全体のエントロピーは次のようなものとなる。

$$
Entropy(S)=\sum_{i=1}^{n}w_iEntropy(P_i)
$$

#### 決定木を選定する

　過学習を防ぐために**早期終了**（early stopping）することを、決定木の**選定**（pruning）と呼ぶ。しかし、決定木をもっと大きなサイズに成長させていれば、微細ながら重要なパターンを学習していたかもしれない。このアプローチには、そうしたパターンを見逃したかどうかを知るすべがない。

　これに変わる**事後剪定**（post-pruning）という手法では、決定木をわざと大きすぎるサイズに成長させ、より適切なサイズになるように葉ノードを刈り込む。多くの場合、事後剪定は事前剪定よりも効果的なアプローチとなる。

　C5.0 アルゴリズムの利点の１つは、剪定について［極めて妥当なデフォルト設定を使って決定の多くを自動的に処理する］ことをしている。訓練データを過学習するサイズに決定木を成長させた後、分類誤差にほとんど影響を与えないノードや枝を刈り込む。場合によっては、分類誤差を減らすために枝全体を決定木の上の方に移動したり、より単純な決定に置き換えたりする。このような接ぎ木のプロセスを**部分技の腹接ぎまたは高接ぎ**（subtree raising）、**部分木の置換**（subtree replacement）と呼ぶ。

## 5.2 例：C5.0の決定木を使ってあぶない融資を特定する

```{r, message=FALSE, warning=FALSE}

if(! require(tidyverse)){
    install.packages('tidyverse', quiet = TRUE)
}
library(tidyverse)
```

### ステップ１：データを収集する

```{r データの読み込み}
credit <- read.csv('https://raw.githubusercontent.com/dataspelunking/MLwR/master/Machine%20Learning%20with%20R%20(3rd%20Ed.)/Chapter05/credit.csv', stringsAsFactors = TRUE)
```

### ステップ２：データの調査と前処理

最初の数行を確認する。

```{r}
str(credit)
```

　1,000この観測値があり17の特徴量で構成されている。

融資の焦げ付きを予測するのに使えそうな特徴量は２つ

-   当座預金口座の残高（checking_balance）
-   普通預金口座の残高（savings_balance）

```{r}
table(credit$checking_balance)
```

```{r}
table(credit$savings_balance)
```

　なお、この融資データはユーロ導入前のドイツで収集されたデータであるため、通貨はドイツマルク（DM）である。

　このデータには、返済期間（months_loan_duration）や融資額（amount）といった数値の特徴量も含まれている。

```{r}
summary(credit$months_loan_duration)
```

```{r}
summary(credit$amount)
```

　融資額は250マルクから18,424マルク、返済期間は4か月から72か月であり、中央値はそれぞれ2,320マルクと18か月となっている。

　defaultは、借り手が返済期間を守れなかった、あるいは返済不能になったかを示す。このデータセットでは融資の30％が焦げ付いている。

```{r}
table(credit$default)
```

#### データの前処理：訓練データセットとテストデータセットをランダムに作成する

```{r}

# ランダム数列の生成
RNGversion('3.5.2'); set.seed(123)
train_sample <- sample(1000, 900)

# 数列の確認（一部）
str(train_sample)
```

　教師データと検証データにデータを分割する。

```{r}
credit_train <- credit[train_sample, ]
credit_test <- credit[-train_sample, ]
```

　大きな偏りがないか、分割結果を確認する。

```{r 教師データ}
credit_train$default %>% table() %>% prop.table()
```

```{r 検証データ}
credit_test$default %>% table() %>% prop.table()
```

### ステップ３：モデルを訓練する

```{r ライブラリのインストール, message=TRUE, warning=FALSE}

if(! require(C50)){
    install.packages('C50', quiet = TRUE)
}
library(C50)
```

C5.0ライブラリを訓練する。

```{r ライブラリの訓練}

credit_model <- C5.0(credit_train %>% select(- default), credit_train$default)
credit_model
```

　決定木が行った決定を確認する。

```{r}
summary(credit_model)
```

　この学習では900個の訓練データのうち、133個を除くっデータが正しく分類され、誤分類率が14.8%であることを示している。合計で35個のデータがyesと誤分類（偽陽性）されており、98個のデータがnoと誤分類（偽陰性）されている。

### ステップ４：モデルの性能を評価する

```{r ライブラリの読み込み, message=FALSE, warning=FALSE}

if(! require(gmodels)){
    install.packages('gmodels', quiet = TRUE)
}
library('gmodels')
```

```{r テストデータの予測と評価}

credit_pred <- predict(credit_model, credit_test)

CrossTable(credit_test$default,
           credit_pred,
           prop.chisq = FALSE,
           prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('actual default', 'predicted default')
           )
```

　テストデータの予測結果の正解率（Accuracy）は73%だが、適合率（Precision）は42％にとどまる。焦げ付く融資の半分以上を見逃してしまっている。

### ステップ５：モデルの性能を向上させる

　C5.0に実装されているアダブーストの機能を利用する。アダブーストは、多くの決定木を構築し、各インスタンスにとって最良と思えるクラスに投票させるプロセス。「単純な学習器（弱学習器）」をいくつか組み合わせることで、予測性能を向上させる。

#### 決定木の正解率を向上させる

```{r ブースティングによる学習}
credit_boost10 <- C5.0(credit_train %>% select(-default), credit_train$default, trials = 10)

credit_boost10
```

```{r 学習結果の確認}
summary(credit_boost10)
```

　ブースティングにより、学習データにおける正解率が13.9%から3.8%に向上した。このモデルを使用して検証データの予測精度を確認する。

```{r 検証データによる精度検証}
credit_boost_pred10 <- predict(credit_boost10, credit_test)

CrossTable(credit_test$default,
           credit_boost_pred10,
           prop.chisq = FALSE,
           prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('actulal default', 'predicted default')
           )
```

　ブースティングを実施する前の正解率（Accuracy）が73%から82%に向上した。適合率（Precision）も42%から61%に向上したが、債務不履行の取りこぼしとしてはまだ大きい。

#### 誤分類のコストを指定する

　偽陰性のコストが高く付くことから、C5.0アルゴリズムでは、よりコストの掛かる誤分類を阻止するために、様々な種類の誤分類にペナルティを与えることができる。これらのペナルティは**コスト行列**（cost matrix）で指定する。

```{r コストマトリックスの定義}
matrix_dimensions <- list(c('no', 'yes'), c('no', 'yes'))
names(matrix_dimensions) <- c('predicted', 'actual')

# コストマトリックスの中身の確認
matrix_dimensions

# ペナルティー値の設定
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2, dimnames = matrix_dimensions)
error_cost
```

　このペナルティにて再びモデルを学習させて、偽陰性を低下させられるかを確かめる。

```{r 検証データの予測と精度確認}

# ペナルティを用いて学習器を訓練
credit_cost <- C5.0(
    credit_train %>% select(- default),
    credit_train$default,
    costs = error_cost
)

# 学習したモデルで検証データで予測
credit_cost_pred <- predict(credit_cost, credit_test)

# 予測結果の精度検証
CrossTable(credit_test$default,
           credit_cost_pred,
           prop.chisq = FALSE,
           prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('actual default', 'predict default')
           )
```

　ブースティングを追加したモデルと比較すると正解率は低下しており、63%となっている。ただし誤分類の種類は異なっている。以前のモデルでは、債務不履行の正解率はそれぞれ42%と61%だったが、今回は79%となった。

## 5.3　分類ルールを理解する

　分類ルールは、ラベル付けされていないインスタンスにクラスを割り当てるif-else形式の論理文として知識を表現する。これらのルールは前件（antecedent）および後件（consequent）として指定され、「～が起きた場合には～が起きる」という文を組み立てる。

　分類ルール学習器は、決定木学習器に非常に近いもので、よく同じようなタスクに使われる。

-   機械のハードウェアの故障につながる条件を特定する
-   顧客をセグメント化するために人々のグループの主な特徴を定義する
-   株式市場での株価の大幅な下落や上昇の前触れとなる条件を見つけ出す

　一方で、分類ルール学習器には、決定木との明らかな違いもある。決定木は枝を順番にたどりながら決定を行わなければならないが、分類ルール学習器は命題であり、事実を記載した個々の文と同じ様に読むことができる。

### 5.3.1　分離統治

　分類ルールアルゴリズムは、**分離統治**（separate and conquer）というヒューリスティクスを利用する。このプロセスでは、訓練データのサブセットをカバーするルールを特定し、このサブセットを残りのデータから切り離す。ルールを追加してはサブセットを切り離すという作業を、データセット全体がカバーされ、残っているインスタンスがなくなるまで繰り返す。

### 5.3.2　１Rアルゴリズム

　ZeroRという学習器の存在する。ZeroRは、特徴量を考慮せず、ルールを全く学習しない分類ルール学習器である。ラベル付けされていないデータごとに、その特徴量の値にかかわらず、最も共通するクラスを予測する。現実的な用途はほとんどないが、他のより高度な分類ルール学習器のベースラインとなる。

　1Rアルゴリズム（1R algorithm）は、ルールを1つ選択することでZeroRを改善したもので、One RuleまたはOneRとも呼ばれる。これでも単純すぎるように思えるかもしれないが、思ったよりも性能が良い傾向にある。実証調査によれば、現実の多くのタスクにおいて、このアルゴリズムの正解率がはるかに高度なアルゴリズムの正解率に匹敵することがある。

　次の表に、1Rアルゴリズムの長所と短所をまとめる。

+----------------------------------------------------------+------------------------------+
| **長所**                                                 | **短所**                     |
+==========================================================+==============================+
| -   理解しやすく読みやすいルールを1つだけ生成する        | -   特徴量を１つしか使わない |
| -   驚くほど性能が良いことが多い                         | -   おそらく単純すぎる \|    |
| -   より複雑なアルゴリズムのベンチマークとして利用できる |                              |
+----------------------------------------------------------+------------------------------+

### 5.3.3　RIPPERアルゴリズム

　初期の分類ルール学習アルゴリズムは、「とにかく遅い」、「ノイズが多いと正解率が低くなりがち」という2つの問題があった。IREP（Incremental Reduced Error Pruning）アルゴリズムは、事前剪定と事後剪定を組み合わせたもので、ルールを非常に複雑なレベルにまで成長させ、それらを選定してから、データセットのデータを分割するといったものだった。これにより分類ルール学習器の性能向上に貢献したが、決定木の性能には及ばないことが多かった。RIPPER（Repeated Incremental Pruning to Produce Error Reduction）はIREPのルールの精製方法に改良を加えたもので、決定木と同じかそれ以上の性能を獲得した。

　次の表にRIPPERの長所と短所を示した。記載した長所と短所は決定木のものとだいたい一致している。最大の利点は、蹴って技よりもコストのかからないモデルを構築できる可能性がある。

+----------------------------------------------------+------------------------------------------------------------+
| **長所**                                           | **短所**                                                   |
+:===================================================+:===========================================================+
| -   理解しやすく読みやすいルールを生成する         | -   常識や専門知識に逆らう感じのルールを生成することがある |
| -   大規模でノイズの多いデータセットでも効率的     | -   数値データの処理には適していない                       |
| -   一般に同等の決定木よりも単純なモデルを生成する | -   より複雑なモデルよりも性能が劣ることがある             |
+----------------------------------------------------+------------------------------------------------------------+

　RIPPERアルゴリズムは、次の３ステップのプロセスがある。

1.  成長
2.  剪定
3.  最適化

　成長フェーズでは、分離統治法に基づき、データのサブセットが完全に分類されるか、分割に利用できる特徴量を使い切るまで、ルールに条件を貪欲に追加していく。決定木と同様に、次の分割に使う特徴量は情報利得に基づいて決める。これ以上ルールを具体化してもエントロピーが減らなくなったら、すぐにルールの剪定を開始する。そして終了条件が満たされるまでに手順１と手順２を繰り返す。終了条件が満たされたら、様々なヒューリスティクスを用いて一連のルール全体を最適化する。

### 5.3.4　決定木から分類ルールへ

　分類ルールは決定木からも直接作成できる。葉ノードからルートに向かって枝をさかのぼっていくと、一連の決定が可能となる。これらの決定は１つのルールにまとめることができる。

> #### TIPS {#sec-tips}
>
> C50パッケージのC5.0関数を使ってモデル訓練する場合は、rules = TRUE を指定すると、モデルの構築に分類ルールが使われる

### 5.3.5　貪欲な決定木と分類ルール

　決定木と分類ルール学習器は**貪欲な学習器**（greedy leaner）と呼ばれる。これはデータを早い者勝ちで使うことが由来である。決定木が用いる分割統治と分類ルール学習機が用いる分離統治のヒューリスティクス（ひらめきや思いつき）には共通点がある。どちらも、最も均一性の高いグループを見つけ出し、次に均一性の高いグループを見つけ出すといった容量で、すべてのデータが分類されるまでグループを一つずつ作成していく。

　この貪欲なアプローチの欠点は、特定のデータセットにとって最適なルール、最も正確なルール、あるいは最も少ない数のルールの生成が保証されないことである。

　また、決定木と文類ルール学習器はどちらも貪欲な学習ヒューリスティクスを用いるが、ルールの構築方法に微妙な違いがある。決定木では特徴量に基づいて分割統治を行った場合、この分割によって作成されたサブセットは再統治の対象にならず、更に分割されるだけである。決定木は過去の決定の履歴に永久に制限される。対照的に分離統治では、ルールが特定された後、ルールのすべての条件を持ってしてもカバーされないデータは再統治の対象になる。このため、分類ルール学習器は決定木よりもルールの数を減らせることが多い。ただし、このデータの再利用は分類ルール学習器の計算量が決定木よりも若干多いことを意味する。

## 5.4　例：分類ルール学習器を使って毒キノコを識別する

　分類ルール学習アルゴリズムの特徴の１つは、理解しやすいルールを生成することであるため、この分類タスクにうってつけに思える。しかし、ルールが役立つかどうかはその正確さ次第である。

### ステップ1：データを収集する

```{r}

# マッシュルームデータの読み込み
mushrooms <- read.csv('https://raw.githubusercontent.com/dataspelunking/MLwR/master/Machine%20Learning%20with%20R%20(3rd%20Ed.)/Chapter05/mushrooms.csv', stringsAsFactors = TRUE)

str(mushrooms)
```

　veil_type という特徴量は因子のレベルが１つしかないので削除する。本家であるUCIのWebページには、この特徴量のレベルとしてpartialとuniversalの２種類が記載されている。ダウンロードしたデータは何らかの理由で正しくコード化されていない状態のデータだと思われる。このデータにおいては有益ではない特徴のため、データから取り除く。

### ステップ2：データの調査と前処理

```{r}
# veil_typeを削除
mushrooms <- mushrooms %>% select(- veil_type)
```

　mushroomsデータフレームのtypeの特徴量を確認する。

```{r}
table(mushrooms$type)
```

　このデータは8,214個のサンプルがあり、あらゆる野生のキノコを完全に収録されているものとする。この事により、未知のキノコの有毒／無毒を予測する必要がなく、記録されているキノコを正確に分類できれば良いこととなる。したがって、訓練データの一部をテストのために分けておく必要はない。

### ステップ3：モデルを訓練する

　仮にこのデータでZeroR分類器を訓練するとしたら、ZeroRは何を予測するだろうか。ZeroRは特徴量を完全に無視し、単に目的変数の最頻値（モード）を予測するため、すべてのキノコを「食べられるキノコであると予測するだろう。ほぼ半分のサンプルが毒キノコであることを考えると、キノコ狩りで中毒患者や死者が出ることになるため、当然ながらそれほどの有益な分類器ではない。一般に公開してもよいほど安全なアドバイスを提供するには、このベンチマークよりはるかによいルールを作成する必要がある。それと同時に、これらのルールは単純で覚えやすいものではなければならない。

　ルールは単純であっても有益なことがある。そこで、このデータ瀬戸で非常に単純な分類ルール学習器の性能を調べてみる。ここで使うのは1R 分類器である。この分類器は、変数としての重要度が最も高い特徴量を1つ選択し、この特徴量を使ってルールを作成する。

　この分類系には、OneRパッケージの1R 実装を使用する。

```{r}
# ライブラリのインストール

if(! require(OneR)){
    install.packages('OneR', quiet = TRUE)
}

library(OneR)
```

```{r}
mushroom_1R <- OneR(type ~ ., data = mushrooms)
mushroom_1R
```

　この出力から、ルールの生成にodor（におい）特徴量が選択されてことがわかる。odor特徴量のalmondやaniseといったカテゴリの値は、キノコがedibleかpoisonousかを判断するためのルールとなる。たとえば、キノコのにおいがfishy、foul、musty、pungent、spicy、あるいはcreosoteである場合、そのキノコは有毒（poisonous）である可能性が高い。これに対し、almondやaniseのようなにおいのする場合は、食べられるキノコである（edible）と予測する。

### ステップ4：モデルの性能を評価する

　この結果から、においを使用したルールにより、8,124このサンプルのうち8,004個（ほぼ90%）が食べられるキノコであると正しく予測されたことがわかる。しかし、100%に届かないうちは安心できない。

　このようなことが起こるかどうかを判断するために、予測値と正解値の混同行列を作成してみる。

```{r}
mushroom_1R_pred <- predict(mushroom_1R, mushrooms, )
table(actual = mushrooms$type, predicted = mushroom_1R_pred)

```

　この出力から、1Rモデルのルールはあまりうまく行っていない。120種類の毒キノコが食べられるキノコに分類されてしまっている。

　R1モデルが特徴量を1つしか使っていないことを考えれば、まずまずの性能である。とはいえ、命がかかっている問題であるので、100%の性能でなければならない。ルールを更に追加すれば、より性能のよい分類器ができるだろうか。

### ステップ5：モデルの視能を向上させる

　より高度な分類ルール学習機では、JRip関数を使うことにする。JRipはRIPPERアルゴリズムのJavaベース実装版である。

```{r}

# ライブラリの読み込み
if(! require(RWeka)){
    install.packages('RWeka', quiet = TRUE)
}

library(RWeka)
```

```{r}

# モデルの訓練
mushroom_JRip <- JRip(type ~ ., data = mushrooms)

mushroom_JRip
```

　JRip分類器はデータセットから9つのルールを学習している。これらのルールについては、プログラミングロジックのif-else文のリストとして考える。

-   においがfoulの場合、そのキノコは有毒である
-   ヒダの大きさがnarrowで、ヒダの色がbuffの場合、そのキノコは有毒である
-   ヒダの大きさがnarrowで、においがpungentの場合、そのキノコは有毒である

　最後の9つ目のルールは、それまでの8つのルールでカバーされなかったキノコは食べられるキノコであることを示している。

　各ルールの右にある数字は、そのルールがカバーしてるサンプルの個数と誤分類の個数を示している。
